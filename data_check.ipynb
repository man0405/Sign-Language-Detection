{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19eb6c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.data_processing import SignLanguageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d883b7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training dataset:\n",
      "Total samples in data_train: 36\n",
      "Found new shape: torch.Size([30, 225]) at index 0 with label 0\n",
      "Shape distribution: {torch.Size([30, 225]): 20}\n",
      "\n",
      "Checking test dataset:\n",
      "Total samples in data_test: 9\n",
      "Found new shape: torch.Size([30, 225]) at index 0 with label 0\n",
      "Shape distribution: {torch.Size([30, 225]): 9}\n"
     ]
    }
   ],
   "source": [
    "# Check dataset for inconsistent tensor shapes\n",
    "import torch\n",
    "\n",
    "def check_dataset_consistency(dataset_name):\n",
    "    dataset = SignLanguageDataset(dataset_name)\n",
    "    print(f\"Total samples in {dataset_name}: {len(dataset)}\")\n",
    "    \n",
    "    # Track shapes\n",
    "    shapes = {}\n",
    "    \n",
    "    # Check first few samples\n",
    "    for i in range(min(len(dataset), 20)):\n",
    "        sample, label = dataset[i]\n",
    "        shape = sample.shape\n",
    "        if shape in shapes:\n",
    "            shapes[shape] += 1\n",
    "        else:\n",
    "            shapes[shape] = 1\n",
    "            print(f\"Found new shape: {shape} at index {i} with label {label}\")\n",
    "    \n",
    "    print(f\"Shape distribution: {shapes}\")\n",
    "    \n",
    "    # Check some random samples if dataset is large\n",
    "    if len(dataset) > 20:\n",
    "        import random\n",
    "        indices = random.sample(range(20, len(dataset)), min(10, len(dataset)-20))\n",
    "        for i in indices:\n",
    "            sample, label = dataset[i]\n",
    "            shape = sample.shape\n",
    "            if shape not in shapes:\n",
    "                shapes[shape] = 1\n",
    "                print(f\"Found new shape: {shape} at index {i} with label {label}\")\n",
    "    \n",
    "    return shapes\n",
    "\n",
    "print(\"Checking training dataset:\")\n",
    "train_shapes = check_dataset_consistency(\"data_train\")\n",
    "\n",
    "print(\"\\nChecking test dataset:\")\n",
    "test_shapes = check_dataset_consistency(\"data_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa1073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding samples with shape torch.Size([30, 126]) in training data:\n",
      "\n",
      "Finding samples with shape torch.Size([30, 126]) in test data:\n"
     ]
    }
   ],
   "source": [
    "# Find all samples with shape [30, 126] and identify their paths\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def find_samples_with_shape(dataset_path, target_shape):\n",
    "    found_samples = []\n",
    "    \n",
    "    # Loop through all actions\n",
    "    for action in os.listdir(dataset_path):\n",
    "        if action.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        action_path = os.path.join(dataset_path, action)\n",
    "        if not os.path.isdir(action_path):\n",
    "            continue\n",
    "        \n",
    "        # Loop through all sequences\n",
    "        for sequence in os.listdir(action_path):\n",
    "            if sequence.startswith('.'):\n",
    "                continue\n",
    "                \n",
    "            sequence_path = os.path.join(action_path, sequence)\n",
    "            if not os.path.isdir(sequence_path):\n",
    "                continue\n",
    "            \n",
    "            # Check if this is a valid sequence folder with .npy files\n",
    "            npy_files = [f for f in os.listdir(sequence_path) if f.endswith('.npy')]\n",
    "            if not npy_files:\n",
    "                continue\n",
    "            \n",
    "            # Check the shape of the data\n",
    "            sequence_data = []\n",
    "            for frame_file in sorted(npy_files):\n",
    "                frame_path = os.path.join(sequence_path, frame_file)\n",
    "                frame_data = np.load(frame_path)\n",
    "                sequence_data.append(frame_data)\n",
    "                \n",
    "            sequence_data = torch.tensor(np.array(sequence_data))\n",
    "            \n",
    "            if sequence_data.shape == target_shape:\n",
    "                found_samples.append({\n",
    "                    'path': sequence_path,\n",
    "                    'action': action,\n",
    "                    'sequence': sequence,\n",
    "                    'shape': sequence_data.shape,\n",
    "                    'num_frames': len(npy_files)\n",
    "                })\n",
    "    \n",
    "    return found_samples\n",
    "\n",
    "# Find samples with shape [30, 126] in both train and test datasets\n",
    "target_shape = torch.Size([30, 126])\n",
    "\n",
    "print(\"Finding samples with shape\", target_shape, \"in training data:\")\n",
    "train_samples = find_samples_with_shape(\"data_train\", target_shape)\n",
    "for idx, sample in enumerate(train_samples):\n",
    "    print(f\"{idx+1}. {sample['action']}/{sample['sequence']} - Shape: {sample['shape']}, Frames: {sample['num_frames']}\")\n",
    "\n",
    "print(\"\\nFinding samples with shape\", target_shape, \"in test data:\")\n",
    "test_samples = find_samples_with_shape(\"data_test\", target_shape)\n",
    "for idx, sample in enumerate(test_samples):\n",
    "    print(f\"{idx+1}. {sample['action']}/{sample['sequence']} - Shape: {sample['shape']}, Frames: {sample['num_frames']}\")\n",
    "\n",
    "# Check one of these samples to understand what's different\n",
    "if train_samples or test_samples:\n",
    "    sample_path = train_samples[0]['path'] if train_samples else test_samples[0]['path']\n",
    "    frame_file = sorted(os.listdir(sample_path))[0]  # First frame\n",
    "    frame_path = os.path.join(sample_path, frame_file)\n",
    "    frame_data = np.load(frame_path)\n",
    "    \n",
    "    print(f\"\\nAnalyzing sample frame from: {frame_path}\")\n",
    "    print(f\"Frame shape: {frame_data.shape}\")\n",
    "    print(f\"Data type: {frame_data.dtype}\")\n",
    "    \n",
    "    # Check if we have less data points than expected\n",
    "    if len(frame_data) == 126:\n",
    "        print(\"This frame has exactly 126 data points (likely missing pose data)\")\n",
    "        left_hand = frame_data[:63]\n",
    "        right_hand = frame_data[63:126]\n",
    "        print(f\"Left hand data points: {len(left_hand)}\")\n",
    "        print(f\"Right hand data points: {len(right_hand)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
